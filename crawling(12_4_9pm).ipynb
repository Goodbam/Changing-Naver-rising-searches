{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawling(12/4/9pm).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goodbam/Changing-Naver-rising-searches/blob/master/crawling(12_4_9pm).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tssl247HkHCi",
        "colab_type": "code",
        "outputId": "2b828dea-1e5b-479e-a1b9-e78727b21633",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "!pip install parse"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (4.2.5)\n",
            "Requirement already satisfied: parse in /usr/local/lib/python3.6/dist-packages (1.9.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uxKEDAv_kLKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests                 # url request\n",
        "from lxml.html import parse     # parsing the data as the html form\n",
        "from io import StringIO         # String I/O module\n",
        "\n",
        "THRESHOLD = 16 #limit to check whether they are relative or not\n",
        "NOISE = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnRDApPylNT_",
        "colab_type": "code",
        "outputId": "aea14028-c7b2-4153-cf7f-4f79412db135",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "url = \"https://www.naver.com\"\n",
        "\n",
        "# Get html source\n",
        "text = requests.get(url).text\n",
        "\n",
        "# parsing the data as the html form\n",
        "text_source = StringIO(text)    # read the data as string\n",
        "parsed = parse(text_source)     # source ->parsing the data as the html form \n",
        "\n",
        "#find root node\n",
        "doc = parsed.getroot()\n",
        "\n",
        "# doc.findall(\".//TagName\") => find the tag lists\n",
        "uls = doc.findall('.//ul')\n",
        "\n",
        "#Get the Rising searches\n",
        "ul = uls[10]   \n",
        "spans = ul.findall('.//span')\n",
        "\n",
        "data_list= []  # to save all the keywords\n",
        "\n",
        "cnt = 1\n",
        "for data in spans:\n",
        "  if cnt % 2 == 0:  \n",
        "    print(int((cnt+1)/2),'->',data.text_content().strip())  # show the existing rising searches\n",
        "  cnt +=1  \n",
        "  data_list.append(data.text_content().strip()) #save each keyword\n",
        "    \n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> 이일재\n",
            "2 -> 처음학교로\n",
            "3 -> 황지만\n",
            "4 -> 최소윤\n",
            "5 -> 식품안전나라\n",
            "6 -> 노니 쇳가루\n",
            "7 -> 노니\n",
            "8 -> 개그우먼 김혜선\n",
            "9 -> 이선정\n",
            "10 -> 김혜선\n",
            "11 -> 아일랜드\n",
            "12 -> 광주형 일자리\n",
            "13 -> 2019 수능 등급컷\n",
            "14 -> 비디오스타\n",
            "15 -> 키드밀리\n",
            "16 -> lj\n",
            "17 -> 정혜인\n",
            "18 -> 밴티지 포인트\n",
            "19 -> 캡틴 마블\n",
            "20 -> 정재형\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Xk_oFVcFzQU",
        "colab_type": "code",
        "outputId": "a9dd92c4-7939-493f-b725-a03f9d9dd163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "path='https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=' #This is the url for surfing\n",
        "\n",
        "matrix = [] #to count the score of relationship\n",
        "label = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] #disjoint set\n",
        "\n",
        "cnt1 = 0\n",
        "\n",
        "for i in range(0, 20):\n",
        "  word = data_list[1 + cnt1]\n",
        "  search = path + word #url searching the keyword\n",
        "  text = requests.get(search).text # no worry about encoding url\n",
        "  \n",
        "  row = []\n",
        "  cnt2 = 0\n",
        "  for j in range(0, 20):\n",
        "    if cnt1 != cnt2: #no need to check when they are equivalent\n",
        "      target = data_list[1 + cnt2];\n",
        "      row.append(text.count(target) + 7*word.count(target) - NOISE) \n",
        " \n",
        "      if row[int(cnt2/2)] >= THRESHOLD: #IF they are relative,\n",
        "        print(word, ' and ', target,)\n",
        "        #the representive number should be minimized\n",
        "        \n",
        "        #여기 정규화를 해서 row의합으로 각 row의 값을 나누던지 해보자\n",
        "        #그러려니, 전체적으로 점수 자체가 높은 것은 감안해서 평균을 다시 루트씌우고 곱하든지 고려해보자\n",
        "        #A와 B 관련 , B C 관련 이면 A C는 관련이 있는건가? 이것도 감안\n",
        "        \n",
        "        if label[int(cnt1/2)] < label[int(cnt2/2)]:\n",
        "          label[int(cnt2/2)] = label[int(cnt1/2)]  \n",
        "        \n",
        "        else:\n",
        "          label[int(cnt1/2)] = label[int(cnt2/2)]\n",
        "    \n",
        "    else :\n",
        "      row.append(0)\n",
        "    \n",
        "    cnt2 += 2\n",
        "  \n",
        "  matrix.append(row)  \n",
        "  cnt1 += 2\n",
        "  "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "황지만  and  이선정\n",
            "최소윤  and  키드밀리\n",
            "식품안전나라  and  노니 쇳가루\n",
            "식품안전나라  and  노니\n",
            "노니 쇳가루  and  노니\n",
            "노니  and  lj\n",
            "개그우먼 김혜선  and  김혜선\n",
            "이선정  and  황지만\n",
            "이선정  and  비디오스타\n",
            "이선정  and  lj\n",
            "아일랜드  and  lj\n",
            "비디오스타  and  이선정\n",
            "키드밀리  and  최소윤\n",
            "lj  and  황지만\n",
            "lj  and  이선정\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G4W-z5rSF0Gz",
        "colab_type": "code",
        "outputId": "5cfc441a-0297-40a6-9bf2-7e12ceedf0cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "print('\\n',label,'\\n')\n",
        "\n",
        "print(matrix)\n",
        "\n",
        "size = [0]\n",
        "size = size*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  size[i] = sum(matrix[i])\n",
        "\n",
        "print(size)\n",
        "score =[0]\n",
        "score = score*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  score[label[i] - 1] += 1/(i+1); #label is 1~20 => needed to subtract 1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " [1, 2, 3, 4, 5, 5, 5, 8, 3, 8, 3, 12, 13, 3, 4, 3, 17, 18, 19, 20] \n",
            "\n",
            "[[0, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 104, 9, 0, 0, 0, 10, 2, 13, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 107, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 23, 71, 0, 0, 9, 0, 0, 0, 0, 2, 8, 0, 0, 0, 2], [2, 0, 0, 0, 7, 0, 208, 0, 0, 9, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 5, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 18, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 154, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 45, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 29, 2, 20, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 10, 0, 0, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 18, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 14, 0, 0, 0, 2], [2, 0, 2, 0, 0, 2, 11, 0, 24, 9, 0, 0, 0, 0, 2, 10, 0, 0, 0, 2], [2, 0, 0, 76, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 0, 7, 0, 0, 0, 2], [2, 0, 34, 0, 0, 2, 11, 0, 67, 9, 0, 0, 0, 8, 2, 0, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 1, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 11, 0, 0, 0, 0, 2, 7, 0, 0, 0, 2], [2, 0, 0, 0, 0, 2, 11, 0, 0, 9, 0, 0, 0, 0, 2, 9, 0, 0, 0, 0]]\n",
            "[33, 35, 155, 140, 117, 237, 47, 180, 122, 36, 46, 35, 42, 64, 109, 137, 35, 36, 37, 35]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUTNRYleF0KA",
        "colab_type": "code",
        "outputId": "b6ffedd3-71db-4594-eb39-01b2dac019b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "#RESULT\n",
        "print('\\n☆급상승 검색어 순위☆\\n')\n",
        "cnt = 1;\n",
        "\n",
        "#sorting according to SCORE\n",
        "for i in range(0,20):\n",
        "  max = 0\n",
        "  for j in range(1,20):\n",
        "    if score[j] > score[max]:\n",
        "      max = j;\n",
        "  \n",
        "  relative_word = ''\n",
        "  \n",
        "  for j in range(0,20):\n",
        "    if label[j] == max + 1:\n",
        "      relative_word += data_list[1 + 2*j] + ' | ' \n",
        "  \n",
        "  score[max] = 0;\n",
        "  \n",
        "  print(cnt, '. ', relative_word[0:-3])\n",
        "  cnt += 1\n",
        "  if(score.count(0) == 20):\n",
        "    break  "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "☆급상승 검색어 순위☆\n",
            "\n",
            "1 .  이일재\n",
            "2 .  황지만 | 이선정 | 아일랜드 | 비디오스타 | lj\n",
            "3 .  식품안전나라 | 노니 쇳가루 | 노니\n",
            "4 .  처음학교로\n",
            "5 .  최소윤 | 키드밀리\n",
            "6 .  개그우먼 김혜선 | 김혜선\n",
            "7 .  광주형 일자리\n",
            "8 .  2019 수능 등급컷\n",
            "9 .  정혜인\n",
            "10 .  밴티지 포인트\n",
            "11 .  캡틴 마블\n",
            "12 .  정재형\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Se8kjTi5qAY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}