{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawling(12/7/10am).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goodbam/Changing-Naver-rising-searches/blob/master/crawling(12_7_10am).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tssl247HkHCi",
        "colab_type": "code",
        "outputId": "70df8e30-8be5-4867-e515-915bf6f8565c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "!pip install parse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lxml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 6.3MB/s \n",
            "\u001b[?25hInstalling collected packages: lxml\n",
            "Successfully installed lxml-4.2.5\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/98/809e53e5778c59c4af9eb920605e7a8ab439407efbe89a6d51a46efd1937/parse-1.9.0.tar.gz\n",
            "Building wheels for collected packages: parse\n",
            "  Running setup.py bdist_wheel for parse ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ef/db/c6/18568a2cc574848f3996ac4552241fbec046b7be29feb2077d\n",
            "Successfully built parse\n",
            "Installing collected packages: parse\n",
            "Successfully installed parse-1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uxKEDAv_kLKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests                 # url request\n",
        "from lxml.html import parse     # parsing the data as the html form\n",
        "from io import StringIO         # String I/O module\n",
        "\n",
        "THRESHOLD = 28 #limit to check whether they are relative or not\n",
        "NOISE = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnRDApPylNT_",
        "colab_type": "code",
        "outputId": "460c886f-5f53-4702-9a34-542864ef22fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "url = \"https://www.naver.com\"\n",
        "\n",
        "# Get html source\n",
        "text = requests.get(url).text\n",
        "\n",
        "# parsing the data as the html form\n",
        "text_source = StringIO(text)    # read the data as string\n",
        "parsed = parse(text_source)     # source ->parsing the data as the html form \n",
        "\n",
        "#find root node\n",
        "doc = parsed.getroot()\n",
        "\n",
        "# doc.findall(\".//TagName\") => find the tag lists\n",
        "uls = doc.findall('.//ul')\n",
        "\n",
        "#Get the Rising searches\n",
        "ul = uls[10]   \n",
        "spans = ul.findall('.//span')\n",
        "\n",
        "data_list= []  # to save all the keywords\n",
        "\n",
        "cnt = 1\n",
        "for data in spans:\n",
        "  if cnt % 2 == 0:  \n",
        "    print(int((cnt+1)/2),'->',data.text_content().strip())  # show the existing rising searches\n",
        "  cnt +=1  \n",
        "  data_list.append(data.text_content().strip()) #save each keyword\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> 이유몰\n",
            "2 -> 7호선\n",
            "3 -> 서수연\n",
            "4 -> 이지안\n",
            "5 -> 대설\n",
            "6 -> 한고은\n",
            "7 -> 조여정\n",
            "8 -> 킴스닷컴\n",
            "9 -> 리퍼브매장\n",
            "10 -> 화웨이\n",
            "11 -> 고고싱\n",
            "12 -> 박항서\n",
            "13 -> 이은희\n",
            "14 -> 해빙\n",
            "15 -> 떠리몰\n",
            "16 -> 베트남 필리핀\n",
            "17 -> 아리따움\n",
            "18 -> 스즈키컵\n",
            "19 -> 카카오톡 PC버전\n",
            "20 -> 연애의 맛\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Xk_oFVcFzQU",
        "colab_type": "code",
        "outputId": "28a6c506-5626-4724-e715-37acb799be28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "cell_type": "code",
      "source": [
        "path='https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=' #This is the url for surfing\n",
        "\n",
        "matrix = [] #to count the score of relationship\n",
        "label = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] #disjoint set\n",
        "\n",
        "cnt1 = 0\n",
        "\n",
        "for i in range(0, 20):\n",
        "  word = data_list[1 + cnt1]\n",
        "  search = path + word #url searching the keyword\n",
        "  text = requests.get(search).text # no worry about encoding url\n",
        "  \n",
        "  row = []\n",
        "  cnt2 = 0\n",
        "  for j in range(0, 20):\n",
        "    if cnt1 != cnt2: #no need to check when they are equivalent\n",
        "      target = data_list[1 + cnt2];\n",
        "      row.append(text.count(target) + 7*word.count(target) - NOISE) \n",
        "      \n",
        "      if row[int(cnt2/2)] >= THRESHOLD: #IF they are relative,\n",
        "        print(word, ' and ', target,)\n",
        "        #the representive number should be minimized\n",
        "        \n",
        "        if label[int(cnt1/2)] < label[int(cnt2/2)]:\n",
        "          label[int(cnt2/2)] = label[int(cnt1/2)]  \n",
        "        \n",
        "        else:\n",
        "          label[int(cnt1/2)] = label[int(cnt2/2)]\n",
        "    \n",
        "    else :\n",
        "      row.append(0)\n",
        "    \n",
        "    cnt2 += 2\n",
        "  \n",
        "  matrix.append(row)  \n",
        "  cnt1 += 2\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "이유몰  and  킴스닷컴\n",
            "서수연  and  이지안\n",
            "서수연  and  연애의 맛\n",
            "이지안  and  서수연\n",
            "이지안  and  이은희\n",
            "이지안  and  연애의 맛\n",
            "조여정  and  한고은\n",
            "킴스닷컴  and  이유몰\n",
            "리퍼브매장  and  이유몰\n",
            "이은희  and  이지안\n",
            "이은희  and  연애의 맛\n",
            "베트남 필리핀  and  박항서\n",
            "베트남 필리핀  and  스즈키컵\n",
            "스즈키컵  and  박항서\n",
            "연애의 맛  and  서수연\n",
            "연애의 맛  and  이지안\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G4W-z5rSF0Gz",
        "colab_type": "code",
        "outputId": "3cef3f6a-eade-4ea3-9b26-1713be20e499",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n',label,'\\n')\n",
        "\n",
        "for i in range(20):\n",
        "  print(matrix[i])\n",
        "\n",
        "size = [0]\n",
        "size = size*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  size[i] = sum(matrix[i])\n",
        " \n",
        "print(size)\n",
        "score =[0]\n",
        "score = score*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  score[label[i] - 1] += 1/(i+1); #label is 1~20 => needed to subtract 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " [1, 2, 3, 3, 5, 6, 6, 1, 1, 10, 11, 12, 3, 14, 15, 12, 17, 12, 19, 3] \n",
            "\n",
            "[0, 0, 2, 2, 0, 2, 2, 32, 23, 2, 0, 2, 0, 0, 2, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 0, 28, 0, 2, 2, 0, 0, 2, 0, 2, 18, 0, 0, 0, 0, 2, 0, 69]\n",
            "[2, 0, 44, 0, 0, 2, 2, 0, 0, 2, 0, 2, 65, 0, 0, 0, 0, 2, 0, 54]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 0, 15, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 75, 0, 0, 0, 2, 0, 2, 1, 0, 0, 0, 0, 2, 0, 2]\n",
            "[52, 0, 2, 2, 0, 2, 2, 0, 20, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[32, 0, 2, 2, 0, 2, 2, 3, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 17, 0, 23, 0, 2]\n",
            "[2, 0, 19, 72, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 45]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[22, 0, 2, 2, 0, 2, 2, 7, 3, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 59, 0, 0, 0, 0, 0, 70, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 88, 0, 0, 0, 9, 0, 0, 0, 2]\n",
            "[2, 0, 2, 2, 0, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 2]\n",
            "[2, 0, 31, 32, 0, 2, 2, 0, 0, 2, 0, 2, 23, 0, 0, 0, 0, 2, 0, 0]\n",
            "[73, 18, 127, 175, 18, 29, 90, 88, 51, 16, 18, 54, 148, 18, 48, 143, 18, 111, 18, 98]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUTNRYleF0KA",
        "colab_type": "code",
        "outputId": "692379c7-de45-41d8-cd1b-0c24bc1728c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#RESULT\n",
        "print('\\n☆급상승 검색어 순위☆\\n')\n",
        "cnt = 1;\n",
        "\n",
        "#sorting according to SCORE\n",
        "for i in range(0,20):\n",
        "  max = 0\n",
        "  for j in range(1,20):\n",
        "    if score[j] > score[max]:\n",
        "      max = j;\n",
        "  \n",
        "  relative_word = ''\n",
        "  \n",
        "  for j in range(0,20):\n",
        "    if label[j] == max + 1:\n",
        "      relative_word += data_list[1 + 2*j] + ' | ' \n",
        "  \n",
        "  score[max] = 0;\n",
        "  \n",
        "  print(cnt, '. ', relative_word[0:-3])\n",
        "  cnt += 1\n",
        "  if(score.count(0) == 20):\n",
        "    break  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "☆급상승 검색어 순위☆\n",
            "\n",
            "1 .  이유몰 | 킴스닷컴 | 리퍼브매장\n",
            "2 .  서수연 | 이지안 | 이은희 | 연애의 맛\n",
            "3 .  7호선\n",
            "4 .  한고은 | 조여정\n",
            "5 .  박항서 | 베트남 필리핀 | 스즈키컵\n",
            "6 .  대설\n",
            "7 .  화웨이\n",
            "8 .  고고싱\n",
            "9 .  해빙\n",
            "10 .  떠리몰\n",
            "11 .  아리따움\n",
            "12 .  카카오톡 PC버전\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}