{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "crawling(5pm).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Goodbam/Changing-Naver-rising-searches/blob/master/crawling(5pm).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "tssl247HkHCi",
        "colab_type": "code",
        "outputId": "c3a3cf65-3ff7-4d2a-881d-098aeb6fbc4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "!pip install parse"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lxml\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/03/a4/9eea8035fc7c7670e5eab97f34ff2ef0ddd78a491bf96df5accedb0e63f5/lxml-4.2.5-cp36-cp36m-manylinux1_x86_64.whl (5.8MB)\n",
            "\u001b[K    100% |████████████████████████████████| 5.8MB 7.2MB/s \n",
            "\u001b[?25hInstalling collected packages: lxml\n",
            "Successfully installed lxml-4.2.5\n",
            "Collecting parse\n",
            "  Downloading https://files.pythonhosted.org/packages/b6/98/809e53e5778c59c4af9eb920605e7a8ab439407efbe89a6d51a46efd1937/parse-1.9.0.tar.gz\n",
            "Building wheels for collected packages: parse\n",
            "  Running setup.py bdist_wheel for parse ... \u001b[?25l-\b \bdone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/ef/db/c6/18568a2cc574848f3996ac4552241fbec046b7be29feb2077d\n",
            "Successfully built parse\n",
            "Installing collected packages: parse\n",
            "Successfully installed parse-1.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uxKEDAv_kLKH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import requests                 # url request\n",
        "from lxml.html import parse     # parsing the data as the html form\n",
        "from io import StringIO         # String I/O module\n",
        "\n",
        "THRESHOLD = 28 #limit to check whether they are relative or not\n",
        "NOISE = 9"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnRDApPylNT_",
        "colab_type": "code",
        "outputId": "df8c77b6-50b9-465e-9ff8-f45955b64872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "cell_type": "code",
      "source": [
        "url = \"https://www.naver.com\"\n",
        "\n",
        "# Get html source\n",
        "text = requests.get(url).text\n",
        "\n",
        "# parsing the data as the html form\n",
        "text_source = StringIO(text)    # read the data as string\n",
        "parsed = parse(text_source)     # source ->parsing the data as the html form \n",
        "\n",
        "#find root node\n",
        "doc = parsed.getroot()\n",
        "\n",
        "# doc.findall(\".//TagName\") => find the tag lists\n",
        "uls = doc.findall('.//ul')\n",
        "\n",
        "#Get the Rising searches\n",
        "ul = uls[10]   \n",
        "spans = ul.findall('.//span')\n",
        "\n",
        "data_list= []  # to save all the keywords\n",
        "\n",
        "cnt = 1\n",
        "for data in spans:\n",
        "  if cnt % 2 == 0:  \n",
        "    print(int((cnt+1)/2),'->',data.text_content().strip())  # show the existing rising searches\n",
        "  cnt +=1  \n",
        "  data_list.append(data.text_content().strip()) #save each keyword\n",
        "    \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 -> 연신내 맥도날드\n",
            "2 -> 이창섭\n",
            "3 -> 공범\n",
            "4 -> 스즈키컵\n",
            "5 -> 화웨이\n",
            "6 -> 2018 스즈키컵\n",
            "7 -> 굿바이싱글\n",
            "8 -> 김지명\n",
            "9 -> 홍수현\n",
            "10 -> 영화 공범\n",
            "11 -> 권다현\n",
            "12 -> 김미화\n",
            "13 -> 영리병원\n",
            "14 -> 선덕고 김지명\n",
            "15 -> 삼성전자 임원인사\n",
            "16 -> 견미리\n",
            "17 -> 삼성 임원인사\n",
            "18 -> 베트남 필리핀\n",
            "19 -> 나비\n",
            "20 -> 손흥민 골\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0Xk_oFVcFzQU",
        "colab_type": "code",
        "outputId": "fda83d9a-e097-4799-9032-44fdf8e4e90d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "cell_type": "code",
      "source": [
        "path='https://search.naver.com/search.naver?sm=top_hty&fbm=1&ie=utf8&query=' #This is the url for surfing\n",
        "\n",
        "matrix = [] #to count the score of relationship\n",
        "label = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20] #disjoint set\n",
        "\n",
        "cnt1 = 0\n",
        "\n",
        "for i in range(0, 20):\n",
        "  word = data_list[1 + cnt1]\n",
        "  search = path + word #url searching the keyword\n",
        "  text = requests.get(search).text # no worry about encoding url\n",
        "  \n",
        "  row = []\n",
        "  cnt2 = 0\n",
        "  for j in range(0, 20):\n",
        "    if cnt1 != cnt2: #no need to check when they are equivalent\n",
        "      target = data_list[1 + cnt2];\n",
        "      row.append(text.count(target) + 7*word.count(target) - NOISE) \n",
        "      \n",
        "      if row[int(cnt2/2)] >= THRESHOLD: #IF they are relative,\n",
        "        print(word, ' and ', target,)\n",
        "        #the representive number should be minimized\n",
        "        \n",
        "        if label[int(cnt1/2)] < label[int(cnt2/2)]:\n",
        "          label[int(cnt2/2)] = label[int(cnt1/2)]  \n",
        "        \n",
        "        else:\n",
        "          label[int(cnt1/2)] = label[int(cnt2/2)]\n",
        "    \n",
        "    else :\n",
        "      row.append(0)\n",
        "    \n",
        "    cnt2 += 2\n",
        "  \n",
        "  matrix.append(row)  \n",
        "  cnt1 += 2\n",
        "  "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2018 스즈키컵  and  스즈키컵\n",
            "영화 공범  and  공범\n",
            "선덕고 김지명  and  김지명\n",
            "베트남 필리핀  and  스즈키컵\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "G4W-z5rSF0Gz",
        "colab_type": "code",
        "outputId": "61e9e37e-72e2-4110-9e14-ebe70d1f8bbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('\\n',label,'\\n')\n",
        "\n",
        "for i in range(20):\n",
        "  print(matrix[i])\n",
        "\n",
        "size = [0]\n",
        "size = size*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  size[i] = sum(matrix[i])\n",
        " \n",
        "print(size)\n",
        "score =[0]\n",
        "score = score*20\n",
        "\n",
        "for i in range(0,20):\n",
        "  score[label[i] - 1] += 1/(i+1); #label is 1~20 => needed to subtract 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " [1, 2, 3, 4, 5, 4, 7, 8, 9, 3, 11, 12, 13, 8, 15, 16, 17, 4, 19, 20] \n",
            "\n",
            "[0, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 0, 9, 0, 0, 0, 9, 0, 6, 0, 0, 2, 0, 0, 3, 0, 0, 0, 0]\n",
            "[4, 0, 9, 0, 0, 6, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 5, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 100, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 6, 0, 0]\n",
            "[4, 0, 11, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 0, 0, 0, 0, 0, 2, 11, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 155, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 95, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 3, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 4, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 54, 0, 1, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[4, 0, 9, 9, 0, 0, 0, 9, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]\n",
            "[29, 33, 33, 35, 33, 130, 35, 35, 33, 179, 33, 33, 31, 119, 36, 33, 37, 79, 33, 33]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "QUTNRYleF0KA",
        "colab_type": "code",
        "outputId": "91345a8d-c294-45c3-8821-c279c932e22c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "#RESULT\n",
        "print('\\n☆급상승 검색어 순위☆\\n')\n",
        "cnt = 1;\n",
        "\n",
        "#sorting according to SCORE\n",
        "for i in range(0,20):\n",
        "  max = 0\n",
        "  for j in range(1,20):\n",
        "    if score[j] > score[max]:\n",
        "      max = j;\n",
        "  \n",
        "  relative_word = ''\n",
        "  \n",
        "  for j in range(0,20):\n",
        "    if label[j] == max + 1:\n",
        "      relative_word += data_list[1 + 2*j] + ' | ' \n",
        "  \n",
        "  score[max] = 0;\n",
        "  \n",
        "  print(cnt, '. ', relative_word[0:-3])\n",
        "  cnt += 1\n",
        "  if(score.count(0) == 20):\n",
        "    break  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "☆급상승 검색어 순위☆\n",
            "\n",
            "1 .  연신내 맥도날드\n",
            "2 .  이창섭\n",
            "3 .  스즈키컵 | 2018 스즈키컵 | 베트남 필리핀\n",
            "4 .  공범 | 영화 공범\n",
            "5 .  화웨이\n",
            "6 .  김지명 | 선덕고 김지명\n",
            "7 .  굿바이싱글\n",
            "8 .  홍수현\n",
            "9 .  권다현\n",
            "10 .  김미화\n",
            "11 .  영리병원\n",
            "12 .  삼성전자 임원인사\n",
            "13 .  견미리\n",
            "14 .  삼성 임원인사\n",
            "15 .  나비\n",
            "16 .  손흥민 골\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}